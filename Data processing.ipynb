{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 343,
     "status": "ok",
     "timestamp": 1631799863588,
     "user": {
      "displayName": "Dung Huynh Ngoc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjtF9gASggrpmCt04dbyL02wo_akQeoBoEj9cCl=s64",
      "userId": "06081186698733625674"
     },
     "user_tz": -600
    },
    "id": "9h9gCvCH9uQd"
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import soundfile as sf\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "import csv\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bZP_EbQqQE5R"
   },
   "source": [
    "# Data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 334347,
     "status": "ok",
     "timestamp": 1631795470578,
     "user": {
      "displayName": "Dung Huynh Ngoc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjtF9gASggrpmCt04dbyL02wo_akQeoBoEj9cCl=s64",
      "userId": "06081186698733625674"
     },
     "user_tz": -600
    },
    "id": "u6TWJvO23sjy",
    "outputId": "ba6239db-7558-4acc-8b72-1d06e1cd6d75"
   },
   "outputs": [],
   "source": [
    "#Download training data\n",
    "#!wget https://www.openslr.org/resources/12/train-clean-100.tar.gz\n",
    "#Download dev data\n",
    "#!wget https://www.openslr.org/resources/12/dev-clean.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68478,
     "status": "ok",
     "timestamp": 1631795539040,
     "user": {
      "displayName": "Dung Huynh Ngoc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjtF9gASggrpmCt04dbyL02wo_akQeoBoEj9cCl=s64",
      "userId": "06081186698733625674"
     },
     "user_tz": -600
    },
    "id": "At7YDSVNNXQy",
    "outputId": "c9add364-2b3b-44f2-ced1-2cf4b0e0316a"
   },
   "outputs": [],
   "source": [
    "#unzip\n",
    "#!tar -xzvf  train-clean-100.tar.gz 2> /dev/null\n",
    "#!tar -xzvf  dev-clean.tar.gz 2> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 564,
     "status": "ok",
     "timestamp": 1631795644279,
     "user": {
      "displayName": "Dung Huynh Ngoc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjtF9gASggrpmCt04dbyL02wo_akQeoBoEj9cCl=s64",
      "userId": "06081186698733625674"
     },
     "user_tz": -600
    },
    "id": "qdFW34ru7jDY",
    "outputId": "5982a605-0e07-4087-eb90-87618ad2e424"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘dev_data’: File exists\n",
      "mkdir: cannot create directory ‘train_data’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir dev_data\n",
    "!mkdir train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1631795644279,
     "user": {
      "displayName": "Dung Huynh Ngoc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjtF9gASggrpmCt04dbyL02wo_akQeoBoEj9cCl=s64",
      "userId": "06081186698733625674"
     },
     "user_tz": -600
    },
    "id": "N41g5_I98PIb"
   },
   "outputs": [],
   "source": [
    "preprocessing_para   = {\n",
    "    \"window_size\" : 20,\n",
    "    \"step_size\" : 10,\n",
    "    \"data_dir\": \"./LibriSpeech/\",\n",
    "    \"data_train_dir\": \"./train_data/\",\n",
    "    \"data_dev_dir\": \"./dev_data/\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1631795644280,
     "user": {
      "displayName": "Dung Huynh Ngoc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjtF9gASggrpmCt04dbyL02wo_akQeoBoEj9cCl=s64",
      "userId": "06081186698733625674"
     },
     "user_tz": -600
    },
    "id": "tUBLO0ww5vEh"
   },
   "outputs": [],
   "source": [
    "directory = \"LibriSpeech/train-clean-100/\"\n",
    "dir_walk = list(os.walk(directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1631795644615,
     "user": {
      "displayName": "Dung Huynh Ngoc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjtF9gASggrpmCt04dbyL02wo_akQeoBoEj9cCl=s64",
      "userId": "06081186698733625674"
     },
     "user_tz": -600
    },
    "id": "bC3EfcQx-Q0f"
   },
   "outputs": [],
   "source": [
    "character_map = utils.character_mapping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1631795644616,
     "user": {
      "displayName": "Dung Huynh Ngoc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjtF9gASggrpmCt04dbyL02wo_akQeoBoEj9cCl=s64",
      "userId": "06081186698733625674"
     },
     "user_tz": -600
    },
    "id": "ZD82K6ccCJB3"
   },
   "outputs": [],
   "source": [
    "def log_linear_specgram(audio, sample_rate, window_size=20,\n",
    "                        step_size=10, eps=1e-10):\n",
    "\n",
    "    nperseg = int(round(window_size * sample_rate / 1e3))\n",
    "    noverlap = int(round(step_size * sample_rate / 1e3))\n",
    "\n",
    "    _, _, spec = signal.spectrogram(audio, fs=sample_rate,\n",
    "                                    window='hann', nperseg=nperseg, noverlap=noverlap,\n",
    "                                    detrend=False)\n",
    "\n",
    "    return np.log(spec.T.astype(np.float32) + eps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1631795644950,
     "user": {
      "displayName": "Dung Huynh Ngoc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjtF9gASggrpmCt04dbyL02wo_akQeoBoEj9cCl=s64",
      "userId": "06081186698733625674"
     },
     "user_tz": -600
    },
    "id": "gKnT4NSf5oJK"
   },
   "outputs": [],
   "source": [
    "\n",
    "def data_processing(directory, ds = \"train\"):\n",
    "  num_hours = 0\n",
    "  dir_walk = list(os.walk(directory))\n",
    "  filename = []\n",
    "  spec_length = []\n",
    "  labels_length  = []\n",
    "  labels = []\n",
    "\n",
    "  for root, dirs, files in tqdm(dir_walk):\n",
    "    for file in files:\n",
    "      if file[-4:] == '.txt':\n",
    "        with open(os.path.join(root, file), 'r') as f:\n",
    "          for line in f.readlines():\n",
    "            sections = line.split(' ')\n",
    "            audio, sr = sf.read(os.path.join(root, sections[0] + '.flac'))\n",
    "            num_hours += (len(audio) / sr) / 3600\n",
    "            spec = log_linear_specgram(audio, sr, window_size = preprocessing_para['window_size'],step_size=preprocessing_para['step_size'])\n",
    "            if ds ==\"train\":\n",
    "              np.save(os.path.join(preprocessing_para[\"data_train_dir\"], sections[0] + '.npy'), spec)\n",
    "            else:\n",
    "              np.save(os.path.join(preprocessing_para[\"data_dev_dir\"], sections[0] + '.npy'), spec)\n",
    "            ids = [character_map[c] for c in ' '.join(sections[1:]).lower() if c in character_map]\n",
    "\n",
    "            filename.append(sections[0])\n",
    "            spec_length.append(spec.shape[0])\n",
    "            labels_length.append(len(ids))\n",
    "            labels.append(' '.join([str(i) for i in ids]))\n",
    "  df = pd.DataFrame({\n",
    "      \"filename\" : filename,\n",
    "      \"spec_length\": spec_length,\n",
    "      \"labels_length\": labels_length,\n",
    "      \"labels\": labels\n",
    "  })\n",
    "  if ds == \"train\":\n",
    "    df.to_csv(preprocessing_para[\"data_train_dir\"] + ds + \".csv\", index=False)\n",
    "  elif ds == \"dev\":\n",
    "    df.to_csv(preprocessing_para[\"data_dev_dir\"] + ds + \".csv\", index=False)\n",
    "  print(f\"Done\")\n",
    "  print(f\"Hours pre-processed: {str(num_hours)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 377424,
     "status": "ok",
     "timestamp": 1631796022369,
     "user": {
      "displayName": "Dung Huynh Ngoc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjtF9gASggrpmCt04dbyL02wo_akQeoBoEj9cCl=s64",
      "userId": "06081186698733625674"
     },
     "user_tz": -600
    },
    "id": "eQggTzc3BSOa",
    "outputId": "459d04fc-7a97-49b2-fa2e-367b85607907"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 837/837 [02:08<00:00,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Hours pre-processed: 100.5908796527777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_processing(\"LibriSpeech/train-clean-100/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22769,
     "status": "ok",
     "timestamp": 1631796045124,
     "user": {
      "displayName": "Dung Huynh Ngoc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjtF9gASggrpmCt04dbyL02wo_akQeoBoEj9cCl=s64",
      "userId": "06081186698733625674"
     },
     "user_tz": -600
    },
    "id": "SUdn5dzoLMin",
    "outputId": "5a431b70-1c87-4294-dae1-9125526eb4d6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 138/138 [00:08<00:00, 16.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Hours pre-processed: 5.387811319444446\n"
     ]
    }
   ],
   "source": [
    "data_processing(\"./LibriSpeech/dev-clean/\", \"dev\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sl97aQfdQPrR"
   },
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 510,
     "status": "ok",
     "timestamp": 1631796162866,
     "user": {
      "displayName": "Dung Huynh Ngoc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjtF9gASggrpmCt04dbyL02wo_akQeoBoEj9cCl=s64",
      "userId": "06081186698733625674"
     },
     "user_tz": -600
    },
    "id": "btYPxDWmP6MB",
    "outputId": "95251a96-38d4-4d7b-e0e4-4dca2e181ab3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_spec_length: 2451\n",
      "max_label_length: 398\n",
      "number of sample: 28539\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"./train_data/train.csv\")\n",
    "max_spec_length = train_df[\"spec_length\"].max()\n",
    "max_label_length = train_df[\"labels_length\"].max()\n",
    "print(f\"max_spec_length: {max_spec_length}\")\n",
    "print(f\"max_label_length: {max_label_length}\")\n",
    "print(f\"number of sample: {train_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1631796163245,
     "user": {
      "displayName": "Dung Huynh Ngoc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjtF9gASggrpmCt04dbyL02wo_akQeoBoEj9cCl=s64",
      "userId": "06081186698733625674"
     },
     "user_tz": -600
    },
    "id": "rJmhwOmYSPkQ"
   },
   "outputs": [],
   "source": [
    "def create_data_generator(directory, max_input_length, max_label_length, batch_size=8):\n",
    "    x, y, input_lengths, label_lengths = [], [], [], []\n",
    "    with open(os.path.join(directory, \"train.csv\"), 'r') as metadata:\n",
    "        metadata_reader = csv.DictReader(metadata, fieldnames=['filename', 'spec_length', 'labels_length', 'labels'])\n",
    "        next(metadata_reader)\n",
    "        for row in metadata_reader:\n",
    "            audio = np.load(os.path.join(directory, row['filename'] + '.npy'))\n",
    "            x.append(audio)\n",
    "            y.append([int(i) for i in row['labels'].split(' ')])\n",
    "            input_lengths.append(int(row['spec_length']))\n",
    "            label_lengths.append(int(row['labels_length']))\n",
    "            if len(x) == batch_size:\n",
    "                yield {\n",
    "                    'inputs': tf.keras.preprocessing.sequence.pad_sequences(x, maxlen=max_input_length, padding='post'),\n",
    "                    'labels': tf.keras.preprocessing.sequence.pad_sequences(y, maxlen=max_label_length, padding='post'),\n",
    "                    'input_lengths': np.asarray(input_lengths),\n",
    "                    'label_lengths': np.asarray(label_lengths)\n",
    "                }, {\n",
    "                    'ctc': np.zeros([batch_size])\n",
    "                }\n",
    "                x, y, input_lengths, label_lengths = [], [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1631796163678,
     "user": {
      "displayName": "Dung Huynh Ngoc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjtF9gASggrpmCt04dbyL02wo_akQeoBoEj9cCl=s64",
      "userId": "06081186698733625674"
     },
     "user_tz": -600
    },
    "id": "BvKZ6XyPYa2B"
   },
   "outputs": [],
   "source": [
    "training_para = {\n",
    "    \"batch_size\": 32,\n",
    "    \"vocal_size\": len(character_map)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1631796164038,
     "user": {
      "displayName": "Dung Huynh Ngoc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjtF9gASggrpmCt04dbyL02wo_akQeoBoEj9cCl=s64",
      "userId": "06081186698733625674"
     },
     "user_tz": -600
    },
    "id": "a-lMX5SjThUr"
   },
   "outputs": [],
   "source": [
    "data_generator = create_data_generator(directory=\"./train_data/\",\n",
    "                                                 max_input_length=max_spec_length,\n",
    "                                                 max_label_length=max_label_length,\n",
    "                                                 batch_size=training_para['batch_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "feyz1bXZXbBO"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1631796166316,
     "user": {
      "displayName": "Dung Huynh Ngoc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjtF9gASggrpmCt04dbyL02wo_akQeoBoEj9cCl=s64",
      "userId": "06081186698733625674"
     },
     "user_tz": -600
    },
    "id": "eceUbZfR7aVD"
   },
   "outputs": [],
   "source": [
    "def clipped_relu(x):\n",
    "    return tf.keras.activations.relu(x, max_value=20)\n",
    "\n",
    "def ctc_lambda_func(args):\n",
    "    labels, y_pred, input_length, label_length = args\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "def ctc(y_true, y_pred):\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 502,
     "status": "ok",
     "timestamp": 1631799420605,
     "user": {
      "displayName": "Dung Huynh Ngoc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjtF9gASggrpmCt04dbyL02wo_akQeoBoEj9cCl=s64",
      "userId": "06081186698733625674"
     },
     "user_tz": -600
    },
    "id": "ZE8q9HotZfJr"
   },
   "outputs": [],
   "source": [
    "hparams = {\n",
    "\n",
    "    'verbose': 1,\n",
    "\n",
    "    'conv_channels': [100],\n",
    "    'conv_filters': [5],\n",
    "    'conv_strides': [2],\n",
    "\n",
    "    'rnn_units': [64],\n",
    "    'bidirectional_rnn': True,\n",
    "\n",
    "    'future_context': 2,\n",
    "\n",
    "    'use_bn': True,\n",
    "\n",
    "    'learning_rate': 0.001,\n",
    "    \"max_input_length\": max_spec_length,\n",
    "    'vocab_size': len(character_map)\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 497,
     "status": "ok",
     "timestamp": 1631799984230,
     "user": {
      "displayName": "Dung Huynh Ngoc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjtF9gASggrpmCt04dbyL02wo_akQeoBoEj9cCl=s64",
      "userId": "06081186698733625674"
     },
     "user_tz": -600
    },
    "id": "qBA_60Yg17ht"
   },
   "outputs": [],
   "source": [
    "def ds2_gru_model(input_dim=161, fc_size=1024, rnn_size=512, output_dim=29, initialization='glorot_uniform',\n",
    "                  conv_layers=1, gru_layers=5, use_conv=True):\n",
    "    \"\"\" DeepSpeech 2 implementation\n",
    "    Architecture:\n",
    "        Input Spectrogram TIMEx161\n",
    "        1 Batch Normalisation layer on input\n",
    "        1-3 Convolutional Layers\n",
    "        1 Batch Normalisation layer\n",
    "        1-7 BiDirectional GRU Layers\n",
    "        1 Batch Normalisation layer\n",
    "        1 Fully connected Dense\n",
    "        1 Softmax output\n",
    "    Details:\n",
    "       - Uses Spectrogram as input rather than MFCC\n",
    "       - Did not use BN on the first input\n",
    "       - Network does not dynamically adapt to maximum audio size in the first convolutional layer. Max conv\n",
    "          length padded at 2048 chars, otherwise use_conv=False\n",
    "    Reference:\n",
    "        https://arxiv.org/abs/1512.02595\n",
    "    \"\"\"\n",
    "\n",
    "    K.set_learning_phase(1)\n",
    "\n",
    "    input_data = Input(shape=(None, input_dim), name='inputs')\n",
    "    x = BatchNormalization(axis=-1, momentum=0.99, epsilon=1e-3, center=True, scale=True)(input_data)\n",
    "\n",
    "    if use_conv:\n",
    "        conv = ZeroPadding1D(padding=(0, 2048))(x)\n",
    "        for l in range(conv_layers):\n",
    "            x = Conv1D(filters=fc_size, name='conv_{}'.format(l+1), kernel_size=11, padding='valid', activation='relu', strides=2)(conv)\n",
    "    else:\n",
    "        for l in range(conv_layers):\n",
    "            x = TimeDistributed(Dense(fc_size, name='fc_{}'.format(l + 1), activation='relu'))(x)  # >>(?, time, fc_size)\n",
    "\n",
    "    x = BatchNormalization(axis=-1, momentum=0.99, epsilon=1e-3, center=True, scale=True)(x)\n",
    "\n",
    "    for l in range(gru_layers):\n",
    "        x = Bidirectional(GRU(rnn_size, name='fc_{}'.format(l + 1), return_sequences=True, activation='relu', kernel_initializer=initialization),\n",
    "                      merge_mode='sum')(x)\n",
    "\n",
    "    x = BatchNormalization(axis=-1, momentum=0.99, epsilon=1e-3, center=True, scale=True)(x)\n",
    "\n",
    "    # Last Layer 5+6 Time Dist Dense Layer & Softmax\n",
    "    x = TimeDistributed(Dense(fc_size, activation=clipped_relu))(x)\n",
    "    y_pred = TimeDistributed(Dense(output_dim, name=\"y_pred\", activation=\"softmax\"))(x)\n",
    "\n",
    "    # labels = K.placeholder(name='the_labels', ndim=1, dtype='int32')\n",
    "    labels = Input(name='labels', shape=[None,], dtype='int32')\n",
    "    input_length = Input(name='input_lengths', shape=[1], dtype='int32')\n",
    "    label_length = Input(name='label_lengths', shape=[1], dtype='int32')\n",
    "\n",
    "    # Keras doesn't currently support loss funcs with extra parameters\n",
    "    # so CTC loss is implemented in a lambda layer\n",
    "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([labels,\n",
    "                                                                       y_pred,\n",
    "                                                                       input_length,\n",
    "                                                                       label_length])\n",
    "\n",
    "    model = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1560,
     "status": "ok",
     "timestamp": 1631799985780,
     "user": {
      "displayName": "Dung Huynh Ngoc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjtF9gASggrpmCt04dbyL02wo_akQeoBoEj9cCl=s64",
      "userId": "06081186698733625674"
     },
     "user_tz": -600
    },
    "id": "rjMSLt7K2Bhz",
    "outputId": "818f49e1-247d-46da-f43b-eacaa7d409bc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/utopia/anaconda3/envs/py37/lib/python3.7/site-packages/keras/backend.py:401: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
      "2021-09-17 11:47:39.030340: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-17 11:47:39.034480: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-17 11:47:39.034999: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-17 11:47:39.035827: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-17 11:47:39.036819: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zer"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer fc_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer fc_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer fc_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer fc_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer fc_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer fc_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "o\n",
      "2021-09-17 11:47:39.037445: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-17 11:47:39.038037: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-17 11:47:39.299321: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-17 11:47:39.299809: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-17 11:47:39.300262: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-17 11:47:39.300699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22154 MB memory:  -> device: 0, name: GeForce RTX 3090, pci bus id: 0000:09:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer fc_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer fc_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer fc_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer fc_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer fc_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer fc_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer fc_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer fc_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer fc_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "model = ds2_gru_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 663
    },
    "executionInfo": {
     "elapsed": 112589,
     "status": "error",
     "timestamp": 1631800098363,
     "user": {
      "displayName": "Dung Huynh Ngoc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjtF9gASggrpmCt04dbyL02wo_akQeoBoEj9cCl=s64",
      "userId": "06081186698733625674"
     },
     "user_tz": -600
    },
    "id": "gi4X8dDOenRQ",
    "outputId": "b75b5af7-bce2-4237-fcb2-a5021feef237"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/utopia/anaconda3/envs/py37/lib/python3.7/site-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "2021-09-17 11:47:40.241969: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-17 11:47:45.980844: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8200\n",
      "2021-09-17 11:47:46.508904: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2021-09-17 11:47:46.509323: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2021-09-17 11:47:46.509334: W tensorflow/stream_executor/gpu/asm_compiler.cc:77] Couldn't get ptxas version string: Internal: Couldn't invoke ptxas --version\n",
      "2021-09-17 11:47:46.509801: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2021-09-17 11:47:46.509830: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2021-09-17 11:47:47.011707: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 168s 16s/step - loss: 1187.0886\n",
      "Epoch 2/2\n",
      "10/10 [==============================] - 159s 16s/step - loss: 712.5758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9f4d31f850>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=hparams['learning_rate'], beta_1=0.9, beta_2=0.999, epsilon=1e-8, clipnorm=5)\n",
    "model.compile(optimizer=optimizer, loss=ctc)\n",
    "model.fit_generator(data_generator, epochs=2,steps_per_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 297,
     "status": "ok",
     "timestamp": 1631799662878,
     "user": {
      "displayName": "Dung Huynh Ngoc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjtF9gASggrpmCt04dbyL02wo_akQeoBoEj9cCl=s64",
      "userId": "06081186698733625674"
     },
     "user_tz": -600
    },
    "id": "KYlCE_8y0rjw",
    "outputId": "be145024-14b2-4747-edcb-b6cb911bc2cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, None, 29) dtype=float32 (created by layer 'time_distributed_1')>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.get_layer('ctc').input[1]\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "executionInfo": {
     "elapsed": 12415,
     "status": "ok",
     "timestamp": 1631780138525,
     "user": {
      "displayName": "Dung Huynh Ngoc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjtF9gASggrpmCt04dbyL02wo_akQeoBoEj9cCl=s64",
      "userId": "06081186698733625674"
     },
     "user_tz": -600
    },
    "id": "r4-7i4Wj6T0B"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 492,
     "status": "ok",
     "timestamp": 1631799421093,
     "user": {
      "displayName": "Dung Huynh Ngoc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjtF9gASggrpmCt04dbyL02wo_akQeoBoEj9cCl=s64",
      "userId": "06081186698733625674"
     },
     "user_tz": -600
    },
    "id": "Rlc4aEYHZWN-",
    "outputId": "46dbb5db-6516-4f38-f167-f3fab05243b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "input_data = tf.keras.layers.Input(name='inputs', shape=[hparams['max_input_length'], 161])\n",
    "x = input_data\n",
    "if hparams['use_bn']:\n",
    "          x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.ZeroPadding1D(padding=(0, hparams['max_input_length']))(x)\n",
    "for i in range(len(hparams['conv_channels'])):\n",
    "  x = tf.keras.layers.Conv1D(hparams['conv_channels'][i], hparams['conv_filters'][i], strides=hparams['conv_strides'][i], activation='relu', padding='same')(x)\n",
    "if hparams['use_bn']:\n",
    "  x = tf.keras.layers.BatchNormalization()(x)\n",
    "for h_units in hparams['rnn_units']:\n",
    "  if hparams['bidirectional_rnn']:\n",
    "    h_units = int(h_units / 2)\n",
    "  gru = tf.keras.layers.GRU(h_units, activation='relu', return_sequences=True)\n",
    "  if hparams['bidirectional_rnn']:\n",
    "    gru = tf.keras.layers.Bidirectional(gru, merge_mode='sum')\n",
    "  x = gru(x)\n",
    "if hparams['use_bn']:\n",
    "  x = tf.keras.layers.BatchNormalization()(x)\n",
    "if hparams['future_context'] > 0:\n",
    "  if hparams['future_context'] > 1:\n",
    "    x = tf.keras.layers.ZeroPadding1D(padding=(0, hparams['future_context'] - 1))(x)\n",
    "  x = tf.keras.layers.Conv1D(100, hparams['future_context'], activation='relu')(x)\n",
    "y_pred = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(hparams['vocab_size'] + 1, activation='sigmoid'))(x)\n",
    "\n",
    "labels = tf.keras.layers.Input(name='labels', shape=[None], dtype='float32')\n",
    "input_length = tf.keras.layers.Input(name='input_lengths', shape=[1], dtype='float32')\n",
    "label_length = tf.keras.layers.Input(name='label_lengths', shape=[1], dtype='float32')\n",
    "\n",
    "loss_out = Lambda(ctc_lambda_func, name='ctc')([labels, y_pred, input_length, label_length])\n",
    "model = tf.keras.Model(inputs=[input_data, labels, input_length, label_length], outputs=[loss_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1631780139500,
     "user": {
      "displayName": "Dung Huynh Ngoc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjtF9gASggrpmCt04dbyL02wo_akQeoBoEj9cCl=s64",
      "userId": "06081186698733625674"
     },
     "user_tz": -600
    },
    "id": "C2Bkfe7E62xr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1631780139501,
     "user": {
      "displayName": "Dung Huynh Ngoc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjtF9gASggrpmCt04dbyL02wo_akQeoBoEj9cCl=s64",
      "userId": "06081186698733625674"
     },
     "user_tz": -600
    },
    "id": "OFCzYaXR-08O"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1631780139501,
     "user": {
      "displayName": "Dung Huynh Ngoc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjtF9gASggrpmCt04dbyL02wo_akQeoBoEj9cCl=s64",
      "userId": "06081186698733625674"
     },
     "user_tz": -600
    },
    "id": "-D5yBVYm_LgA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1631780139502,
     "user": {
      "displayName": "Dung Huynh Ngoc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjtF9gASggrpmCt04dbyL02wo_akQeoBoEj9cCl=s64",
      "userId": "06081186698733625674"
     },
     "user_tz": -600
    },
    "id": "96jYDorNAPwv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1631780139502,
     "user": {
      "displayName": "Dung Huynh Ngoc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjtF9gASggrpmCt04dbyL02wo_akQeoBoEj9cCl=s64",
      "userId": "06081186698733625674"
     },
     "user_tz": -600
    },
    "id": "Kt3EH6dGAVW-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "executionInfo": {
     "elapsed": 25187,
     "status": "error",
     "timestamp": 1631796491804,
     "user": {
      "displayName": "Dung Huynh Ngoc",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjtF9gASggrpmCt04dbyL02wo_akQeoBoEj9cCl=s64",
      "userId": "06081186698733625674"
     },
     "user_tz": -600
    },
    "id": "HffNYLusbntb",
    "outputId": "e6f76594-679c-42d9-96a4-3302b2e19c1d"
   },
   "outputs": [
    {
     "ename": "CancelledError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-47ab6775b173>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCancelledError\u001b[0m:  [_Derived_]RecvAsync is cancelled.\n\t [[{{node model_1/ctc/Log/_64}}]] [Op:__inference_train_function_37902]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "model.fit(data_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xCtbmjlUgnIa"
   },
   "outputs": [],
   "source": [
    "       "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMGY9KYsURsKnfo6IWd0APy",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "deepspeech.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
